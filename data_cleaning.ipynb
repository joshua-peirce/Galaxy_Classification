{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f675448-5a51-4875-808d-b69e0b0bbd21",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "## Data cleaning lends itself more to a jupyter notebook, hence the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23cd2126-8bea-4ae7-ae87-0b4e151edb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff0fe484-94bb-42d2-9b61-c2d8d972438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting h5 to csv\n",
    "#df = pd.read_hdf(\"Galaxy10_DECals.h5\")\n",
    "\n",
    "#df.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc72296f-8609-4152-b07f-1b53013f6651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File(\"Galaxy10_DECals.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc0a68ce-d31b-4368-b8c2-6b3b241fac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = f.get(\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25655d0c-346b-4c05-a9a3-d77c49401893",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = f.get(\"ans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3eefc1-4a3b-40ca-ab19-27b111d4951f",
   "metadata": {},
   "source": [
    "### Taking a stratified sample of 1/256th of the images\n",
    "This is what we should run everything on until we are sure our model works well, since getting any result from a 2.7GB dataset is going to take an exorbitant amount of time, so if'we fine tuning parameters, that will work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36f58cbe-578d-4c1e-8be0-5fab150d1fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(0, len(images), 256))\n",
    "imgs = np.array(images[indices])\n",
    "lab = np.array(labels[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70c3ccfa-2f33-4d2b-8954-e5b584ead51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 256, 256, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb47f72-5898-4be3-a328-65e668d9af2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bae187f8-b3a1-4c94-937b-d21c53731c4e",
   "metadata": {},
   "source": [
    "### Taking a stratified sample of 1/35th of the images\n",
    "The super small one is just to make sure the python code works. This larger dataset is for actually tuning hyperparameters where we have enough of a sample to make confident decisions about our dataset.\n",
    "35 seems like a weird number. The reason behind it is github enterprise only lets you have up to 100MB per file, and this is the number that gives us the largest number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0500d71c-81a5-48f9-ba47-c6ca3295ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(0, len(images), 35))\n",
    "np.array(images[indices]).tofile(\"sample_imgs_large.csv\")\n",
    "np.array(labels[indices]).tofile(\"sample_labels_large.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d257bb5-2eab-4bca-af48-54c4d868666e",
   "metadata": {},
   "source": [
    "### The full 2.7GB sample will be run on the Khoury servers to speed up training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
