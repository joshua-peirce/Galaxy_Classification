{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd443cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torchvision\n",
    "\n",
    "# set device\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11986315-b6f0-426d-9da2-91a5df1ce64b",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06883d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read datafile (h5)\n",
    "f = h5py.File(\"Galaxy10_DECals.h5\")\n",
    "images = f.get(\"images\")\n",
    "labels = f.get(\"ans\")\n",
    "img_in = np.array(images)\n",
    "lab_in = np.array(labels)\n",
    "\n",
    "# write data to tensors\n",
    "imgs = torch.from_numpy(img_in)\n",
    "labs = torch.from_numpy(labs)\n",
    "imgs = [x.permute(2, 0, 1) for x in imgs]\n",
    "\n",
    "\n",
    "# data augmentation based on model input\n",
    "MOD_INPUT_SIZE = 224\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomResizedCrop(MOD_INPUT_SIZE),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "imgs = torch.stack([data_transform(imgs[i]) for i in range(len(imgs))])\n",
    "\n",
    "# preparing data as (img, label) tuples\n",
    "dataset = [(i, l) for i, l in zip(imgs, labs)]\n",
    "\n",
    "# separating training and test/validation data\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.1, random_state=10)\n",
    "\n",
    "# wrapping dataloader for training\n",
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2128c736-7d6a-4533-9161-a1228d802b7e",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb3d70e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_119754/3442821343.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel_conv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_conv = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "# num_ftrs = model_conv.classifier[1].in_features\n",
    "# model_conv.classifier = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model_conv.parameters(), lr=learning_rate)\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    loss_l = []\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X.to(device))\n",
    "        loss = loss_fn(pred, y.to(device))\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Record metrics\n",
    "        loss_l.append(loss)\n",
    "        \n",
    "        print(batch)\n",
    "        if batch % 64 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    return loss_l\n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X.to(device))\n",
    "            test_loss += loss_fn(pred, y.to(device)).item()\n",
    "            correct += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bceab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.281027  [   64/15962]\n",
      "loss: 2.242123  [ 4160/15962]\n",
      "loss: 2.249239  [ 8256/15962]\n",
      "loss: 2.232876  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 21.3%, Avg loss: 2.200167 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.193328  [   64/15962]\n",
      "loss: 2.183141  [ 4160/15962]\n",
      "loss: 2.157067  [ 8256/15962]\n",
      "loss: 2.134340  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 29.5%, Avg loss: 2.096284 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.067110  [   64/15962]\n",
      "loss: 2.035029  [ 4160/15962]\n",
      "loss: 2.021489  [ 8256/15962]\n",
      "loss: 2.023919  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 35.7%, Avg loss: 1.916379 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.983937  [   64/15962]\n",
      "loss: 1.705292  [ 4160/15962]\n",
      "loss: 1.728369  [ 8256/15962]\n",
      "loss: 1.647164  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 41.4%, Avg loss: 1.701234 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.787027  [   64/15962]\n",
      "loss: 1.594134  [ 4160/15962]\n",
      "loss: 1.671380  [ 8256/15962]\n",
      "loss: 1.590800  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 48.8%, Avg loss: 1.524169 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.775622  [   64/15962]\n",
      "loss: 1.654634  [ 4160/15962]\n",
      "loss: 1.446598  [ 8256/15962]\n",
      "loss: 1.332338  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 1.390559 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.371346  [   64/15962]\n",
      "loss: 1.327423  [ 4160/15962]\n",
      "loss: 1.205530  [ 8256/15962]\n",
      "loss: 1.185573  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 1.270169 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.212862  [   64/15962]\n",
      "loss: 1.195148  [ 4160/15962]\n",
      "loss: 1.139034  [ 8256/15962]\n",
      "loss: 1.071011  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 58.7%, Avg loss: 1.194974 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.265950  [   64/15962]\n",
      "loss: 1.318379  [ 4160/15962]\n",
      "loss: 1.127404  [ 8256/15962]\n",
      "loss: 0.776822  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 60.7%, Avg loss: 1.126369 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.053941  [   64/15962]\n",
      "loss: 1.134044  [ 4160/15962]\n",
      "loss: 1.201276  [ 8256/15962]\n",
      "loss: 1.143466  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 1.061727 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.971503  [   64/15962]\n",
      "loss: 1.161738  [ 4160/15962]\n",
      "loss: 0.904755  [ 8256/15962]\n",
      "loss: 1.086815  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 0.995099 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.062851  [   64/15962]\n",
      "loss: 1.114985  [ 4160/15962]\n",
      "loss: 0.849572  [ 8256/15962]\n",
      "loss: 0.986183  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 67.0%, Avg loss: 0.956734 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.945683  [   64/15962]\n",
      "loss: 0.871444  [ 4160/15962]\n",
      "loss: 1.009978  [ 8256/15962]\n",
      "loss: 1.014887  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.929419 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.771880  [   64/15962]\n",
      "loss: 0.802405  [ 4160/15962]\n",
      "loss: 1.121978  [ 8256/15962]\n",
      "loss: 0.878672  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.913038 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.820219  [   64/15962]\n",
      "loss: 0.857437  [ 4160/15962]\n",
      "loss: 0.880307  [ 8256/15962]\n",
      "loss: 0.843564  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 68.4%, Avg loss: 0.893247 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.779534  [   64/15962]\n",
      "loss: 0.771387  [ 4160/15962]\n",
      "loss: 0.829322  [ 8256/15962]\n",
      "loss: 0.772794  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 70.1%, Avg loss: 0.866978 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.576207  [   64/15962]\n",
      "loss: 0.863444  [ 4160/15962]\n",
      "loss: 0.824793  [ 8256/15962]\n",
      "loss: 0.677638  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.850903 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.100390  [   64/15962]\n",
      "loss: 0.822761  [ 4160/15962]\n",
      "loss: 0.943451  [ 8256/15962]\n",
      "loss: 0.688497  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.851424 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.702196  [   64/15962]\n",
      "loss: 0.695253  [ 4160/15962]\n",
      "loss: 0.649565  [ 8256/15962]\n",
      "loss: 0.765721  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 71.6%, Avg loss: 0.851431 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.741979  [   64/15962]\n",
      "loss: 0.848941  [ 4160/15962]\n",
      "loss: 0.537852  [ 8256/15962]\n",
      "loss: 0.833263  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 71.3%, Avg loss: 0.820387 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.941861  [   64/15962]\n",
      "loss: 0.749826  [ 4160/15962]\n",
      "loss: 0.729826  [ 8256/15962]\n",
      "loss: 0.604210  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 72.8%, Avg loss: 0.811218 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.780886  [   64/15962]\n",
      "loss: 0.793969  [ 4160/15962]\n",
      "loss: 0.716169  [ 8256/15962]\n",
      "loss: 0.596375  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 73.1%, Avg loss: 0.786656 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.525126  [   64/15962]\n",
      "loss: 0.670914  [ 4160/15962]\n",
      "loss: 0.620028  [ 8256/15962]\n",
      "loss: 0.668908  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.773414 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.518212  [   64/15962]\n",
      "loss: 0.823410  [ 4160/15962]\n",
      "loss: 0.684515  [ 8256/15962]\n",
      "loss: 1.083455  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.790195 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.544589  [   64/15962]\n",
      "loss: 0.742488  [ 4160/15962]\n",
      "loss: 0.530490  [ 8256/15962]\n",
      "loss: 0.682692  [12352/15962]\n",
      "Test Error: \n",
      " Accuracy: 73.2%, Avg loss: 0.776720 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "epoch_l = list(range(epochs))\n",
    "data_seen = range(len(train_dataloader.dataset)*epochs)\n",
    "test_l = []\n",
    "correct_l = []\n",
    "lost_tot = []\n",
    "for t in epoch_l:\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    lost_l = train_loop(train_dataloader, model_conv, loss_fn, optimizer, device)\n",
    "    lost_tot.extend(lost_l)\n",
    "    test_loss, correct = test_loop(test_dataloader, model_conv, loss_fn, device)\n",
    "    test_l.append(test_loss)\n",
    "    correct_l.append(correct)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bcf2f38-810c-4c93-a212-eef156d7ea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_conv, 'effnet_tl.pth')\n",
    "torch.save(model_conv.state_dict(), 'effnetweights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b177a0c-90a9-4411-adb9-b9ecdf08d3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
